<!doctype html>
<html>
<head>
	<meta charset="utf-8">
	<title> Audio Visualization </title>
</head>
<body>		
	<h1> Visualize Audio from Microphone Input </h1>
	<p>Web audio API example: takes audio input from microphone visulizes the waveform and spectrogram in real-time. </p>
	
	<button id='freeze_button' onclick="toggleFreezeAnimation()">Freeze</button>	  

	<p><canvas id='wave_view' style="background: white;"></canvas></p>
	<p><canvas id='spec_view' style="background: white;"></canvas></p>

	<script>	
	var context;
	var myAudioBuffer = null;
	var analyser;
	
	var wave_view, spec_view;
	var WIDTH = 1024;
	var HEIGHT = 256;

	var freeze_status = false;

	//
	window.onload=function(){		
		// canvas 
		wave_view = document.getElementById("wave_view");
		spec_view = document.getElementById("spec_view");
		wave_view.width =  WIDTH;
		wave_view.height = HEIGHT;
		spec_view.width =  WIDTH;
		spec_view.height = HEIGHT;	
		
		// create audio context
		window.AudioContext = window.AudioContext || window.webkitAudioContext;
		context = new AudioContext();
		
		// analyzer
	    analyser = context.createAnalyser();
	    analyser.fftSize = 2048;
		analyser.smoothingTimeConstant = 0;
	}
	
	
	function draw_wave() {		
		// 2d canvas context
		var drawContext = wave_view.getContext('2d');
		
		// fill rectangular
		drawContext.fillStyle = 'rgb(200, 200, 200)';
		drawContext.fillRect(0, 0, WIDTH, HEIGHT);

		// drawing line setting
		drawContext.lineWidth = 2;
		drawContext.strokeStyle = 'rgb(0, 0, 0)';
		drawContext.beginPath();
				
		// get samples 
		var dataArray = new Uint8Array(analyser.frequencyBinCount*2);
		analyser.getByteTimeDomainData(dataArray);
		
		var sliceWidth = WIDTH * 1.0 / dataArray.length;
		var x = 0;
		
		for (var i = 0; i < dataArray.length; i++) {
	        var v = dataArray[i] / 256.0;
	        var y = v * HEIGHT;

	    	if(i === 0) {
	        	drawContext.moveTo(x, y);
	        } else {
	        	drawContext.lineTo(x, y);
	        }

	        x += sliceWidth;
		}
		
		// last touch
		drawContext.lineTo(wave_view.width, wave_view.height/2);
		drawContext.stroke();
		
		// queue for next callback
		if ( freeze_status == false ) {
			window.requestAnimationFrame(draw_wave);
		}
	}
	
	function draw_spec() {
		// 2d canvas context
		var drawContext = spec_view.getContext('2d');
		
		// fill rectangular
		drawContext.fillStyle = 'rgb(100, 100, 100)';
		drawContext.fillRect(0, 0, WIDTH, HEIGHT);

		// drawing line setting
		drawContext.lineWidth = 2;
		drawContext.strokeStyle = 'rgb(0, 0, 0)';
		drawContext.beginPath();
				
		// get samples 
		var dataArray = new Uint8Array(analyser.frequencyBinCount);
		analyser.getByteFrequencyData(dataArray);
		
		var sliceWidth = WIDTH * 1.0 / dataArray.length;
		var x = 0;
		
		for (var i = 0; i < dataArray.length; i++) {
	        var v = dataArray[i] / 128.0;
	        var y = HEIGHT - v * HEIGHT/2;

	    	if(i === 0) {
	        	drawContext.moveTo(x, y);
	        } else {
	        	drawContext.lineTo(x, y);
	        }

	        x += sliceWidth;
		}
		
		// last touch
		drawContext.lineTo(draw_spec.width, draw_spec.height/2);
		drawContext.stroke();

		
/*
		// get samples 
		var dataArray = new Uint8Array(analyser.frequencyBinCount);
		analyser.getByteFrequencyData(dataArray);
		
		
		var barWidth = (WIDTH / dataArray.length) * 2.5;
		var barHeight;
		var x = 0;	
		
		for(var i = 0; i < dataArray.length; i++) {
			barHeight = dataArray[i];

//			drawContext.fillStyle = 'rgb(' + (barHeight+100) + ',50,50)';
			drawContext.fillStyle = 'rgb(50,50,50)';
			drawContext.fillRect(x, HEIGHT-barHeight/2, barWidth, barHeight);
			x += barWidth + 1;
			
			if (x > WIDTH)
				break;
		}
*/		
		// queue for next callback
		if ( freeze_status == false ) {
			window.requestAnimationFrame(draw_spec);
		}
	}
	

	
	if (!navigator.getUserMedia)
		navigator.getUserMedia = (navigator.getUserMedia({audio: true}) || navigator.webkitGetUserMedia || navigator.mediaDevices.getUserMedia || navigator.msGetUserMedia);
							  
	if (!navigator.getUserMedia)
		alert("Error: getUserMedia not supported!");
						
	// get audio input streaming 				 
	navigator.getUserMedia({audio: true}, onStream, onStreamError)

	// successCallback
	function onStream(stream) {
	    var input = context.createMediaStreamSource(stream);
		

		// autoplay policy
		if (context.state === 'suspended') {
			context.resume();
		}

		// Connect graph
		input.connect(analyser);
							  
		// Don't pass through if you hear audio feedback
//		input.connect(context.destination);

		// visualize audio
		draw_wave();
		draw_spec();	
	}
	
	// errorCallback			 
	function onStreamError(error) {
		console.error('Error getting microphone', error);
	}

	function toggleFreezeAnimation() {
		if (freeze_status == true) {
			freeze_status = false;
			window.requestAnimationFrame(draw_wave);			
			window.requestAnimationFrame(draw_spec);			
			var freeze_button = document.getElementById("freeze_button");
			freeze_button.innerHTML = 'freeze';
		}
		else {
			freeze_status = true;
			var freeze_button = document.getElementById("freeze_button");
			freeze_button.innerHTML = 'unfreeze';
		}
	}	
	</script>
</body>
</html>